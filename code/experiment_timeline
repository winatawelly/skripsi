Test 1:
    - Parameters :
        - 22 player ratings (11 from each team)

    - Config 1
        - Default Config
        - 5000 generations
        - Fitness function used (fitness function 1) :
            def eval_genomes1(genomes, config):
            for genome_id, genome in genomes:
                genome.fitness = 0
                net = neat.nn.FeedForwardNetwork.create(genome, config)
                for xi, xo in zip(xor_inputs, xor_outputs):
                    output = net.activate(xi)
                    output[0] = round((output[0]*10))
                    output[1] = round((output[1]*10))
                    if(xo[0]*10 == output[0] and xo[1]*10 == output[1] ):
                        genome.fitness += 1
                    else :
                        if(xo[0]*10 > xo[1]*10 and output[0] > output[1] ):
                            genome.fitness += 0.5
                        if(xo[0]*10 < xo[1]*10 and output[0] < output[1] ):
                            genome.fitness += 0.5
                        if(xo[0]*10 == xo[1]*10 and output[0] == output[1] ):
                            genome.fitness += 0.5
        - This fitness function gives 1 point if the output produced by network is correct, and 0.5 if the output is wrong but the result is correct
        - Result :
            - Before Backpropagation :
                - NEAT running time per generation = +- 5.685 sec
                - Prediction accuracy = 32 (8%)
                - Winner accuracy = 107 (28%)
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 2738.68
                - Last Epoch Error = 759.556813660297
                - Total Time = +- 264 sec
                - Prediction accuracy = 94 (24.7%)
                - Winner accuracy = 291 (76.5%)
    
    - Config 2
        - Default config
        - 5000 generations
        - Fitness function is changed to fitness function 2 :
            def eval_genomes(genomes, config):
            for genome_id, genome in genomes:
                genome.fitness = 1140
                net = neat.nn.FeedForwardNetwork.create(genome, config)
                for xi, xo in zip(xor_inputs, xor_outputs):
                    output = net.activate(xi)
                    genome.fitness -= (output[0] - xo[0]) ** 2
                    genome.fitness -= (output[1] - xo[1]) ** 2
        - This fitness function evaluates the fitness score by doing sum of squared error
        - Result :
            - Before Backpropagation
                - NEAT running time per generation = +- 6.733 sec
                - Prediction accuracy = 85 (22%)
                - Winner Accuray = 273  (71%)
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 702.217420208526
                - Last Epoch Error = 460.11051805102335
                - Total Time = +- 234 sec
                - Prediction accuracy = 134 (35.2%)
                - Winner accuracy = 289 (76%)
                
        - Summary :
            this fitness function achieved better result than the previous experiment, however the best network doesn't seem to evolve further

    - Config 3
        - This config disabled the network abilities to remove connection and remove node, allowing population to grow faster
        - 5000 generations
        - Fitness function 2
        - Result :
            - Before Backpropagation :
                - NEAT running time per generation = +- 17.219 sec
                - Score accuracy = 125 (32%)
                - Winner accuracy = 300 (78%)
            - Backpropagation Config :
                - Epoch 44.000
                - Learning Rate = 0.0001
                - Overfitting occurs around epoch 44.000 - 45.000
            - After Backpropagation :
                - First Epoch Error = 530.7183436402343
                - Last Epoch Error = 433.5536763480401
                - Total Time = 181 sec
                - Prediction Accuracy = 155 (40.7 %)
                - Winner Accuracy = 301 (79.2 %)
        - Summary :
            - This config achieved better result than the previous experiment, but the training time is significantly longer
        
Test 2:
    - Parameters
        - 22 player ratings (11 from each team) plus 2 team ratings, total = 24
    
    
    
    Config 1:
        - Same config as Test1-Config3
        - 5000 generations
        - Fitness function 2
        - Result
            - Before Backpropagation :
                - NEAT running time per generation = +- 16.283 sec 
                - Prediction accuracy = 136 (35%)
                - Winner accuracy = 302 (79%)
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 524.5511159411856
                - Last Epoch Error = 351.0110108673137
                - Total Time = 355 sec
                - Prediction Accuracy = 167 (43.9 %)
                - Winner Accuracy = 303 (79.7 %)
        - Summary :
            2 newly added parameters slightly improve the result

    
    Config 2:
        - This config allowed each network to have more than 1 activation function, such as relu, sigmoid, and softmax (in all previous tests, each netowrk can only have 1 activation, which is relu)
        - Fitness function 2
        - Result
            - Prediction accuracy = 113 (30%)
            - Winner accuracy = 286 (75%)
        - Summary :
            - Multiple activation function turned out to be bad, the result is worse than single activation function
        
    Config 3:
        - Becuase there is no improvement from previous test, this config go back to single activation function, but the probability to mutate is bumped to 0.8 from 0,5 in hope the population can grow even faster
        - 5000 generations
        - Fitness function 2
        - Result
            - Before Backpropagation :
                - NEAT running time per generation = +- 19.115 sec
                - Prediction accuracy = 136 (35%)
                - Winner accuracy = 305 (80%)
            - Backpropagation Config : 
                - Epoch = 100000
                - Learning = 0.0001
            - After Backpropagation
                - First Epoch Error = 510.6836877658259 
                - Last Epoch Error = 395.55402206685363
                - Total Time = 482 sec
                - Prediction Accuracy = 161 (42.3%) 
                - Winner Accuracy = 308 (81.%)
        - Summary :
            - sligly better than config 1 

Test 3:
    - Parameters:
        - 22 player ratings + 22 player position + 2 ratings

     Config 1:
        - 1000 generations
        - Fitness function 2
        - One Hot Encoding (1 position = 16 value)
        - Becuase of one hot encoding, the input size becomes very large. 376 inputs. and so the config is adjusted to 700 populations.
        - Result
            - Before Backpropagation :
                - NEAT running time per generation = +- 58.836 sec 
                - Prediction Accuracy = 47 (12%)
                - Winner Accuracy = 194 (51.%)
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 2240.0010633305565
                - Last Epoch Error = 492.4719063138488
                - Total Time = 2269 sec
                - Prediction Accuracy = 122 (32.1%)
                - Winner Accuracy = 306 (80.5%)
        - Summary :
            

    Config 2:
        - 1000 generations
        - Fitness function 2
        - Binary Encoding (1 position = 4 value)
        - i did some experiment by turning node_delete and conn_delete probability to 0.5
        - Result
            - Before Backpropagation :
                - NEAT running time per generation = +- 30.014 sec 
                - Prediction Accuracy = 46 (12%)
                - Winner Accuracy = 223 (58%)
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 1305.7321362145344
                - Last Epoch Error = 469.0066134096415
                - Total Time = 1199 sec
                - Prediction Accuracy = 162 (42.6 %)
                - Winner Accuracy = 304 (80%)
        - Summary :
            

    Config 3:
        - Same config as Test2-Config3
        - 5000 generations
        - Fitness function 2
        - Label Encoding
        - Result
            - Before Backpropagation :
                - NEAT running time per generation = +- 26.645 sec 
                - Prediction accuracy = 90 (23.6%)
                - Winner accuracy = 260 (68.4%)
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 603.855550856583
                - Last Epoch Error = 386.2926339005975
                - Total Time = 789 sec
                - Prediction Accuracy = 153 (40.2%)
                - Winner Accuracy = 299 (78.6%)
        - Summary :

    Config 4:
        - Same config as Test3-Config3
        - 5000 generations
        - Fitness function 2
        - Total Encoding
        - Result
            - Before Backpropagation :
                - NEAT running time per generation = +- 23.645 sec 
                - Prediction accuracy = 
                - Winner accuracy = 
            - Backpropagation Config :
                - Epoch = 100.000
                - Learning Rate = 0.0001
            - After Backpropagation :
                - First Epoch Error = 
                - Last Epoch Error = 
                - Total Time = 665 sec
                - Prediction Accuracy = 153 (45.5%)
                - Winner Accuracy = 310 (81.5%)
        - Summary :
            



